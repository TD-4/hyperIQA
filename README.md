# HyperIQA
âŒšï¸: 2021å¹´4æœˆ1æ—¥

ğŸ“šå‚è€ƒ
- [Blindly Assess Image Quality in the Wild Guided by A Self-Adaptive Hyper Network](https://openaccess.thecvf.com/content_CVPR_2020/papers/Su_Blindly_Assess_Image_Quality_in_the_Wild_Guided_by_a_CVPR_2020_paper.pdf)
---
## 1. ç¯å¢ƒ/Dependencies
- Python 3.6+
- PyTorch 0.4+
- TorchVision
- scipy
(optional for loading specific IQA Datasets)
- csv (KonIQ-10k Dataset)
- openpyxl (BID Dataset)

## 2. ä»£ç ä½¿ç”¨/Usages

###  2.1 æ–‡ä»¶ä»‹ç»

- train_test_IQA.py: è®­ç»ƒçš„ä¸»å‡½æ•°ï¼Œè®­ç»ƒä»æ­¤å¼€å§‹ï¼ˆå®šä¹‰äº†é…ç½®ã€æ•°æ®è·¯å¾„ç­‰ï¼‰
- HyperIQASolver.py: è®­ç»ƒçš„å…·ä½“è¿‡ç¨‹ï¼Œtrainå‡½æ•°æ˜¯è®­ç»ƒçš„ä¸»å‡½æ•°ï¼ˆ1ã€æ•°æ®åŠ è½½ï¼›2ã€æ¨¡å‹å®šä¹‰ï¼›3ã€è¿ç§»å­¦ä¹ ï¼›4ã€æŸå¤±å‡½æ•°ï¼›5ã€ä¼˜åŒ–å™¨å’Œéƒ¨åˆ†å†»ç»“ï¼›6ã€è®­ç»ƒå’Œæµ‹è¯•è¿‡ç¨‹ï¼‰
- data_loader.py: æ•°æ®åŠ è½½éƒ¨åˆ†ï¼Œå®šä¹‰äº†transformerã€Dataloaderã€datasetç­‰å†…å®¹
- folders.py:   æ•°æ®é›†å®šä¹‰éƒ¨åˆ†ï¼Œå®šä¹‰äº†Datasetç±»ï¼Œå³æ•°æ®çš„è¯»å–
- models.py:    æ¨¡å‹å®šä¹‰éƒ¨åˆ†ï¼Œå®šä¹‰äº†IQAç½‘ç»œ
- models2.py:   æ¨¡å‹å®šä¹‰éƒ¨åˆ†ï¼Œå®šä¹‰äº†IQAç½‘ç»œï¼Œä½†ä¸models.pyçš„åŒºåˆ«æ˜¯æ­¤æ–‡ä»¶æŠŠtargetnetèåˆåˆ°äº†hypernetå½“ä¸­ï¼Œä½¿å¾—ä¸¤ä¸ªç½‘ç»œå˜æˆäº†ä¸€ä¸ªæ•´ä½“
- demo.py:  æ¨ç†æ¼”ç¤ºéƒ¨åˆ†ï¼Œè¯»å–ä¸€å¼ å›¾ç‰‡ï¼Œè¾“å‡ºiqaè¯„ä»·
- cls.py/cls_cpu.py:    é¡¹ç›®éœ€æ±‚ï¼Œå¯¹æ•´ä¸ªæ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡è¿›è¡Œæ¨ç†ã€‚ä»£ç é€»è¾‘ä¸demo.pyä¸€è‡´
- export_onnx.py/onnx_run.py:   export_onnx.pyå°†modes.pyä¸­æ¨¡å‹å¯¼å‡º, å¹¶ä½¿ç”¨onnx_run.pyè¿è¡Œ
- export_onnx2.py/onnx_run2.py:   export_onnx2.pyå°†modes2.pyä¸­æ¨¡å‹å¯¼å‡º, å¹¶ä½¿ç”¨onnx_run2.pyè¿è¡Œ
- img-score-tools.py:ä¸ºä¸€ä¸ªæ–‡ä»¶å¤¹è¯„åˆ†çš„å·¥å…·
- img-gen-trainvallist.py:ç”Ÿæˆæ•°æ®é›†çš„ä»£ç 
### 2.2 æ•ˆæœå±•ç¤º/Testing a single image

Predicting image quality with our model trained on the Koniq-10k Dataset.

To run the demo, please download the pre-trained model at [Google drive](https://drive.google.com/file/d/1XBN_-fmUrDMm6nZ-Sf60BJGrDs735_s1/view?usp=sharing) or [Baidu cloud](https://pan.baidu.com/s/1yY3O8DbfTTtUwXn14Mtr8Q) (password: 1ty8), put it in 'pretrained' folder, then run:

```
python demo.py
```

You will get a quality score ranging from 0-100, and a higher value indicates better image quality.

### 2.3 è®­ç»ƒ/Training & Testing on IQA databases

Training and testing our model on the LIVE Challenge Dataset.

```
python train_test_IQA.py
```

Some available options:
* `--dataset`: Training and testing dataset, support datasets: livec | koniq-10k | bid | live | csiq | tid2013.
* `--train_patch_num`: Sampled image patch number per training image.
* `--test_patch_num`: Sampled image patch number per testing image.
* `--batch_size`: Batch size.

When training or testing on CSIQ dataset, please put 'csiq_label.txt' in your own CSIQ folder.
